{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Cleaning\n",
    "\n",
    "In this notebook, I clean the datasets and combine them into a single csv file that can be used later for feature generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages\n",
    "import sys\n",
    "sys.path.append('../../College_Basketball')\n",
    "\n",
    "import pandas as pd\n",
    "import collegebasketball as cbb\n",
    "cbb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Game Scores Data\n",
    "\n",
    "First, we will load in the games scores data from csv files we created earlier. Later, we'll join this data to the team stats datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the data\n",
    "scores_path = '../Data/Scores/'\n",
    "\n",
    "# Initialize some variables\n",
    "regular_season = {}\n",
    "march_madness = {}\n",
    "this_year = 2019\n",
    "\n",
    "# We need to first join datasets from the same year\n",
    "for year in range(2002, this_year):\n",
    "    \n",
    "    # Load the scores datasets\n",
    "    regular_season[year] = pd.read_csv(scores_path + str(year) + '_regular_season.csv')\n",
    "    if year < this_year - 1:\n",
    "        march_madness[year] = pd.read_csv(scores_path + str(year) + '_march.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cleaning the Data\n",
    "\n",
    "Next, we need to edit the school names in the kenpom, basic stats and T-Rank datasets to ensure that they match up with the school names from the scores dataset. We will verify that the names match using the `cbb.check_for_missing_names` command. It checks that each school name in the given team statistics dataset (kenpom, basic stats or T-Rank) is present in the game scores dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location where the files will be saved\n",
    "path = '../Data/'\n",
    "\n",
    "# Store a dataframe of kenpom data for each year in a list\n",
    "kenpom_data = {}\n",
    "TRank_data = {}\n",
    "stats_data = {}\n",
    "\n",
    "# We need to clean each statistics data set\n",
    "for year in range(2002, this_year):\n",
    "    \n",
    "    # Load this year's data and clean up the school names to match up with scores data\n",
    "    data_kenpom = pd.read_csv('{0}Kenpom/{1}_kenpom.csv'.format(path, year))\n",
    "    kenpom_data[year] = cbb.update_kenpom(data_kenpom)\n",
    "    assert len(cbb.check_for_missing_names(regular_season[year], kenpom_data[year], False)) == 0\n",
    "    \n",
    "    # TRank data starts in 2008 and the team name column is called school instead of team\n",
    "    if year > 2007:\n",
    "        data_TRank =  pd.read_csv('{0}TRank/{1}_TRank.csv'.format(path, year))\n",
    "        TRank_data[year] = cbb.update_TRank(data_TRank)\n",
    "        assert len(cbb.check_for_missing_names(regular_season[year], TRank_data[year], False)) == 0\n",
    "        \n",
    "    # Basic stats data starts in 2010\n",
    "    if year > 2009:\n",
    "        data_stats =  pd.read_csv('{0}SportsReference/{1}_stats.csv'.format(path, year))\n",
    "        data_stats = data_stats.rename(index=str, columns={'School': 'Team'})\n",
    "        stats_data[year] = cbb.update_basic(data_stats)\n",
    "        assert len(cbb.check_for_missing_names(regular_season[year], stats_data[year], False)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Conf</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>AdjEM</th>\n",
       "      <th>AdjO</th>\n",
       "      <th>AdjO Rank</th>\n",
       "      <th>AdjD</th>\n",
       "      <th>...</th>\n",
       "      <th>Luck</th>\n",
       "      <th>Luck Rank</th>\n",
       "      <th>OppAdjEM</th>\n",
       "      <th>OppAdjEM Rank</th>\n",
       "      <th>OppO</th>\n",
       "      <th>OppO Rank</th>\n",
       "      <th>OppD</th>\n",
       "      <th>OppD Rank</th>\n",
       "      <th>NCSOS AdjEM</th>\n",
       "      <th>NCSOS AdjEM Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>32.92</td>\n",
       "      <td>117.7</td>\n",
       "      <td>7</td>\n",
       "      <td>84.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>230</td>\n",
       "      <td>10.23</td>\n",
       "      <td>7</td>\n",
       "      <td>107.4</td>\n",
       "      <td>11</td>\n",
       "      <td>97.2</td>\n",
       "      <td>6</td>\n",
       "      <td>2.15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Florida</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SEC</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>31.18</td>\n",
       "      <td>117.2</td>\n",
       "      <td>9</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>332</td>\n",
       "      <td>7.00</td>\n",
       "      <td>41</td>\n",
       "      <td>105.6</td>\n",
       "      <td>63</td>\n",
       "      <td>98.6</td>\n",
       "      <td>36</td>\n",
       "      <td>4.09</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B10</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>29.31</td>\n",
       "      <td>120.8</td>\n",
       "      <td>2</td>\n",
       "      <td>91.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>239</td>\n",
       "      <td>8.86</td>\n",
       "      <td>17</td>\n",
       "      <td>106.7</td>\n",
       "      <td>23</td>\n",
       "      <td>97.8</td>\n",
       "      <td>14</td>\n",
       "      <td>-5.16</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>4.0</td>\n",
       "      <td>B10</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>27.86</td>\n",
       "      <td>121.9</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>197</td>\n",
       "      <td>11.13</td>\n",
       "      <td>3</td>\n",
       "      <td>108.2</td>\n",
       "      <td>5</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.09</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WCC</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>27.81</td>\n",
       "      <td>120.5</td>\n",
       "      <td>3</td>\n",
       "      <td>92.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026</td>\n",
       "      <td>116</td>\n",
       "      <td>4.37</td>\n",
       "      <td>87</td>\n",
       "      <td>105.4</td>\n",
       "      <td>75</td>\n",
       "      <td>101.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5.03</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank        Team  Seed Conf  Wins  Losses  AdjEM   AdjO  AdjO Rank  AdjD  \\\n",
       "0     1  Louisville   1.0   BE    35       5  32.92  117.7          7  84.8   \n",
       "1     2     Florida   3.0  SEC    29       8  31.18  117.2          9  86.0   \n",
       "2     3     Indiana   1.0  B10    29       7  29.31  120.8          2  91.5   \n",
       "3     4    Michigan   4.0  B10    31       8  27.86  121.9          1  94.0   \n",
       "4     5     Gonzaga   1.0  WCC    32       3  27.81  120.5          3  92.7   \n",
       "\n",
       "         ...          Luck  Luck Rank  OppAdjEM  OppAdjEM Rank   OppO  \\\n",
       "0        ...        -0.016        230     10.23              7  107.4   \n",
       "1        ...        -0.089        332      7.00             41  105.6   \n",
       "2        ...        -0.021        239      8.86             17  106.7   \n",
       "3        ...        -0.007        197     11.13              3  108.2   \n",
       "4        ...         0.026        116      4.37             87  105.4   \n",
       "\n",
       "   OppO Rank   OppD  OppD Rank  NCSOS AdjEM  NCSOS AdjEM Rank  \n",
       "0         11   97.2          6         2.15               100  \n",
       "1         63   98.6         36         4.09                62  \n",
       "2         23   97.8         14        -5.16               294  \n",
       "3          5   97.0          3        -3.09               257  \n",
       "4         75  101.0        102         5.03                39  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets take a quick look at one of the datasets\n",
    "kenpom_data[2013].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining the Datasets\n",
    "\n",
    "Now that the school names from each data set matches up, we can join the kenpom and score data to form a single csv file. Additionally, the march scores datasets contained some games that were from postseason tournament games other than the NCAA Tournamnet (for example NIT games are currently in the march scores data). Since, we joined the kenpom data (containing the team seeds) to the game scores, we can find and remove non-NCAA Tounament games from the march datasets by removing games that are not between teams with an NCAA Tournament seed. We will remove these games from the march datasets and add them in the regular season data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 87521 games in the Kenpom dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Home_Score</th>\n",
       "      <th>Away_Score</th>\n",
       "      <th>Rank_Home</th>\n",
       "      <th>Team_Home</th>\n",
       "      <th>Seed_Home</th>\n",
       "      <th>Conf_Home</th>\n",
       "      <th>Wins_Home</th>\n",
       "      <th>...</th>\n",
       "      <th>Luck_Away</th>\n",
       "      <th>Luck Rank_Away</th>\n",
       "      <th>OppAdjEM_Away</th>\n",
       "      <th>OppAdjEM Rank_Away</th>\n",
       "      <th>OppO_Away</th>\n",
       "      <th>OppO Rank_Away</th>\n",
       "      <th>OppD_Away</th>\n",
       "      <th>OppD Rank_Away</th>\n",
       "      <th>NCSOS AdjEM_Away</th>\n",
       "      <th>NCSOS AdjEM Rank_Away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>67</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACC</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>15</td>\n",
       "      <td>14.22</td>\n",
       "      <td>1</td>\n",
       "      <td>111.3</td>\n",
       "      <td>1</td>\n",
       "      <td>97.1</td>\n",
       "      <td>3</td>\n",
       "      <td>17.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>71</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>Florida</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SEC</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>15</td>\n",
       "      <td>14.22</td>\n",
       "      <td>1</td>\n",
       "      <td>111.3</td>\n",
       "      <td>1</td>\n",
       "      <td>97.1</td>\n",
       "      <td>3</td>\n",
       "      <td>17.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>11.0</td>\n",
       "      <td>MWC</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>15</td>\n",
       "      <td>14.22</td>\n",
       "      <td>1</td>\n",
       "      <td>111.3</td>\n",
       "      <td>1</td>\n",
       "      <td>97.1</td>\n",
       "      <td>3</td>\n",
       "      <td>17.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>USC</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "      <td>12</td>\n",
       "      <td>USC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>P10</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>15</td>\n",
       "      <td>14.22</td>\n",
       "      <td>1</td>\n",
       "      <td>111.3</td>\n",
       "      <td>1</td>\n",
       "      <td>97.1</td>\n",
       "      <td>3</td>\n",
       "      <td>17.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>USC</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>71</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>USC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>P10</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>15</td>\n",
       "      <td>14.22</td>\n",
       "      <td>1</td>\n",
       "      <td>111.3</td>\n",
       "      <td>1</td>\n",
       "      <td>97.1</td>\n",
       "      <td>3</td>\n",
       "      <td>17.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year      Home     Away  Home_Score  Away_Score  Rank_Home Team_Home  \\\n",
       "0  2002  Maryland  Arizona          67          71          3  Maryland   \n",
       "1  2002   Florida  Arizona          71          75          7   Florida   \n",
       "2  2002   Wyoming  Arizona          60          68         67   Wyoming   \n",
       "3  2002       USC  Arizona          80          97         12       USC   \n",
       "4  2002       USC  Arizona          71          81         12       USC   \n",
       "\n",
       "   Seed_Home Conf_Home  Wins_Home          ...            Luck_Away  \\\n",
       "0        1.0       ACC         32          ...                0.079   \n",
       "1        5.0       SEC         22          ...                0.079   \n",
       "2       11.0       MWC         22          ...                0.079   \n",
       "3        4.0       P10         22          ...                0.079   \n",
       "4        4.0       P10         22          ...                0.079   \n",
       "\n",
       "   Luck Rank_Away  OppAdjEM_Away  OppAdjEM Rank_Away  OppO_Away  \\\n",
       "0              15          14.22                   1      111.3   \n",
       "1              15          14.22                   1      111.3   \n",
       "2              15          14.22                   1      111.3   \n",
       "3              15          14.22                   1      111.3   \n",
       "4              15          14.22                   1      111.3   \n",
       "\n",
       "   OppO Rank_Away  OppD_Away  OppD Rank_Away  NCSOS AdjEM_Away  \\\n",
       "0               1       97.1               3             17.56   \n",
       "1               1       97.1               3             17.56   \n",
       "2               1       97.1               3             17.56   \n",
       "3               1       97.1               3             17.56   \n",
       "4               1       97.1               3             17.56   \n",
       "\n",
       "   NCSOS AdjEM Rank_Away  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the paths to the data \n",
    "save_path = '../Data/Combined_Data/'\n",
    "\n",
    "# Save the joined tables in dictionaries\n",
    "regular = {}\n",
    "march = {}\n",
    "\n",
    "# We need to first join datasets from the same year\n",
    "for year in range(2002, this_year):\n",
    "    \n",
    "    # Join the dataframes to get kenpom for both home and away team\n",
    "    regular[year] = pd.merge(regular_season[year], kenpom_data[year], left_on='Home', right_on='Team', sort=False)\n",
    "    regular[year] = pd.merge(regular[year], kenpom_data[year], left_on='Away', right_on='Team', \n",
    "                             suffixes=('_Home', '_Away'), sort=False)\n",
    "    \n",
    "    # Do the same for the march data (No march data for this year yet)\n",
    "    if year < this_year - 1:\n",
    "        march[year] = pd.merge(march_madness[year], kenpom_data[year], left_on='Home', right_on='Team', sort=False)\n",
    "        march[year] = pd.merge(march[year], kenpom_data[year], left_on='Away', right_on='Team', \n",
    "                                 suffixes=('_Home', '_Away'), sort=False)\n",
    "\n",
    "        # Move non-tournament games to regular season data\n",
    "        other_games = march[year][march[year]['Seed_Home'].isnull()]\n",
    "        regular[year] = pd.concat([regular[year], other_games], ignore_index=True)\n",
    "        march[year].drop(other_games.index, inplace=True)\n",
    "    \n",
    "    # Add a column to indicate the year\n",
    "    regular[year].insert(0, 'Year', year)\n",
    "    if year < this_year - 1:\n",
    "        march[year].insert(0, 'Year', year)\n",
    "        \n",
    "# Combine the data for every year\n",
    "regular_df = pd.concat(regular, ignore_index=True)\n",
    "march_df = pd.concat(march, ignore_index=True)\n",
    "\n",
    "# Save the data to csv files\n",
    "regular_df.to_csv('{0}Kenpom.csv'.format(save_path))\n",
    "    \n",
    "# Lets take a look at the data set\n",
    "print(\"There are {} games in the Kenpom dataset.\".format(len(regular_df)))\n",
    "regular_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will clean up the team names in the T-Rank data and join it with the game scores data. Additionally, we need to join these data sets with the team Kenpom statistics. This join is necessary because we need to use the Tournament seed attribute in order to clean up the march dataset to only include NCAA Tournament games. It will also be beneficial down the road, during feature generation, for us to have the Kenpom AdjEM stat for each team as a way to judge what outcome of a game is considered an upset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58957 games in the T-Rank dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Home_Score</th>\n",
       "      <th>Away_Score</th>\n",
       "      <th>Rk_Home</th>\n",
       "      <th>Team_Home</th>\n",
       "      <th>Conf_Home</th>\n",
       "      <th>G_Home</th>\n",
       "      <th>W_Home</th>\n",
       "      <th>...</th>\n",
       "      <th>Adj T._Away</th>\n",
       "      <th>Adj T. Rank_Away</th>\n",
       "      <th>WAB_Away</th>\n",
       "      <th>WAB Rank_Away</th>\n",
       "      <th>Team_Home</th>\n",
       "      <th>AdjEM_Home</th>\n",
       "      <th>Seed_Home</th>\n",
       "      <th>Team_Away</th>\n",
       "      <th>AdjEM_Away</th>\n",
       "      <th>Seed_Away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>UT-Martin</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>71</td>\n",
       "      <td>102</td>\n",
       "      <td>252</td>\n",
       "      <td>UT-Martin</td>\n",
       "      <td>OVC</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>70.2</td>\n",
       "      <td>72</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5</td>\n",
       "      <td>UT-Martin</td>\n",
       "      <td>-8.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>31.51</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>143</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>A10</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>70.2</td>\n",
       "      <td>72</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>1.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>31.51</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>Siena</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>58</td>\n",
       "      <td>102</td>\n",
       "      <td>97</td>\n",
       "      <td>Siena</td>\n",
       "      <td>MAAC</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>70.2</td>\n",
       "      <td>72</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5</td>\n",
       "      <td>Siena</td>\n",
       "      <td>7.99</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>31.51</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>Pepperdine</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>53</td>\n",
       "      <td>90</td>\n",
       "      <td>241</td>\n",
       "      <td>Pepperdine</td>\n",
       "      <td>WCC</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>70.2</td>\n",
       "      <td>72</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5</td>\n",
       "      <td>Pepperdine</td>\n",
       "      <td>-6.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>31.51</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>Alabama-Birmingham</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>56</td>\n",
       "      <td>94</td>\n",
       "      <td>66</td>\n",
       "      <td>Alabama-Birmingham</td>\n",
       "      <td>CUSA</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>70.2</td>\n",
       "      <td>72</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama-Birmingham</td>\n",
       "      <td>12.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>31.51</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                Home     Away  Home_Score  Away_Score  Rk_Home  \\\n",
       "0  2008           UT-Martin  Memphis          71         102      252   \n",
       "1  2008            Richmond  Memphis          63          80      143   \n",
       "2  2008               Siena  Memphis          58         102       97   \n",
       "3  2008          Pepperdine  Memphis          53          90      241   \n",
       "4  2008  Alabama-Birmingham  Memphis          56          94       66   \n",
       "\n",
       "            Team_Home Conf_Home  G_Home  W_Home    ...      Adj T._Away  \\\n",
       "0           UT-Martin       OVC      31      17    ...             70.2   \n",
       "1            Richmond       A10      31      16    ...             70.2   \n",
       "2               Siena      MAAC      34      23    ...             70.2   \n",
       "3          Pepperdine       WCC      31      11    ...             70.2   \n",
       "4  Alabama-Birmingham      CUSA      34      23    ...             70.2   \n",
       "\n",
       "   Adj T. Rank_Away  WAB_Away  WAB Rank_Away           Team_Home  AdjEM_Home  \\\n",
       "0                72       8.9              5           UT-Martin       -8.10   \n",
       "1                72       8.9              5            Richmond        1.48   \n",
       "2                72       8.9              5               Siena        7.99   \n",
       "3                72       8.9              5          Pepperdine       -6.39   \n",
       "4                72       8.9              5  Alabama-Birmingham       12.07   \n",
       "\n",
       "   Seed_Home  Team_Away  AdjEM_Away  Seed_Away  \n",
       "0        NaN    Memphis       31.51        1.0  \n",
       "1        NaN    Memphis       31.51        1.0  \n",
       "2       13.0    Memphis       31.51        1.0  \n",
       "3        NaN    Memphis       31.51        1.0  \n",
       "4        NaN    Memphis       31.51        1.0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the paths to the scores data \n",
    "save_path = '../Data/Combined_Data/'\n",
    "\n",
    "# Save the joined tables in dictionaries\n",
    "regular = {}\n",
    "march = {}\n",
    "\n",
    "# We need to first join datasets from the same year\n",
    "for year in range(2008, this_year):\n",
    "    \n",
    "    # Get only the columns we need from the kenpom data\n",
    "    kp = kenpom_data[year][['Team', 'AdjEM', 'Seed']]\n",
    "    \n",
    "    # Join the dataframes to get TRank data and kenpom (seed, adj_em) for both home and away team\n",
    "    regular[year] = pd.merge(regular_season[year], TRank_data[year], left_on='Home', right_on='Team', sort=False)\n",
    "    regular[year] = pd.merge(regular[year], TRank_data[year], left_on='Away', right_on='Team', \n",
    "                             suffixes=('_Home', '_Away'), sort=False)\n",
    "    regular[year] = pd.merge(regular[year], kp, left_on='Home', right_on='Team', sort=False)\n",
    "    regular[year] = pd.merge(regular[year], kp, left_on='Away', right_on='Team', \n",
    "                             suffixes=('_Home', '_Away'), sort=False)\n",
    "    \n",
    "    # Do the same for the march data (No march data for this year yet)\n",
    "    if year < this_year - 1:\n",
    "        march[year] = pd.merge(march_madness[year], TRank_data[year], left_on='Home', right_on='Team', sort=False)\n",
    "        march[year] = pd.merge(march[year], TRank_data[year], left_on='Away', right_on='Team', \n",
    "                                 suffixes=('_Home', '_Away'), sort=False)\n",
    "        march[year] = pd.merge(march[year], kp, left_on='Home', right_on='Team', sort=False)\n",
    "        march[year] = pd.merge(march[year], kp, left_on='Away', right_on='Team', \n",
    "                                 suffixes=('_Home', '_Away'), sort=False)\n",
    "\n",
    "        # Move non-tournament games to regular season data\n",
    "        other_games = march[year][march[year]['Seed_Home'].isnull()]\n",
    "        regular[year] = pd.concat([regular[year], other_games], ignore_index=True)\n",
    "        march[year].drop(other_games.index, inplace=True)\n",
    "    \n",
    "    # Add a column to indicate the year\n",
    "    regular[year].insert(0, 'Year', year)\n",
    "    if year < this_year - 1:\n",
    "        march[year].insert(0, 'Year', year)\n",
    "    \n",
    "# Combine the data for every year\n",
    "regular_df = pd.concat(regular, ignore_index=True)\n",
    "march_df = pd.concat(march, ignore_index=True)\n",
    "\n",
    "# Save the data to csv files\n",
    "regular_df.to_csv('{0}TRank.csv'.format(save_path))\n",
    "    \n",
    "# Lets take a look at one of the data sets\n",
    "print(\"There are {} games in the T-Rank dataset.\".format(len(regular_df)))\n",
    "regular_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will run the same process for the basic statistics as we did for the T-Rank data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 48179 games in the basic statistics dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Home_Score</th>\n",
       "      <th>Away_Score</th>\n",
       "      <th>Team_Home</th>\n",
       "      <th>G_Home</th>\n",
       "      <th>SRS_Home</th>\n",
       "      <th>SOS_Home</th>\n",
       "      <th>Tm._Home</th>\n",
       "      <th>...</th>\n",
       "      <th>STL_Away</th>\n",
       "      <th>BLK_Away</th>\n",
       "      <th>TOV_Away</th>\n",
       "      <th>PF_Away</th>\n",
       "      <th>Team_Home</th>\n",
       "      <th>AdjEM_Home</th>\n",
       "      <th>Seed_Home</th>\n",
       "      <th>Team_Away</th>\n",
       "      <th>AdjEM_Away</th>\n",
       "      <th>Seed_Away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Florida International</td>\n",
       "      <td>UNC</td>\n",
       "      <td>72</td>\n",
       "      <td>88</td>\n",
       "      <td>Florida International</td>\n",
       "      <td>32</td>\n",
       "      <td>-12.81</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>2176</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>210</td>\n",
       "      <td>562</td>\n",
       "      <td>564</td>\n",
       "      <td>Florida International</td>\n",
       "      <td>-14.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNC</td>\n",
       "      <td>13.39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>Albany (NY)</td>\n",
       "      <td>UNC</td>\n",
       "      <td>70</td>\n",
       "      <td>87</td>\n",
       "      <td>Albany (NY)</td>\n",
       "      <td>32</td>\n",
       "      <td>-11.94</td>\n",
       "      <td>-5.53</td>\n",
       "      <td>2007</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>210</td>\n",
       "      <td>562</td>\n",
       "      <td>564</td>\n",
       "      <td>Albany (NY)</td>\n",
       "      <td>-13.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNC</td>\n",
       "      <td>13.39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>William &amp; Mary</td>\n",
       "      <td>UNC</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "      <td>William &amp; Mary</td>\n",
       "      <td>33</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2213</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>210</td>\n",
       "      <td>562</td>\n",
       "      <td>564</td>\n",
       "      <td>William &amp; Mary</td>\n",
       "      <td>6.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNC</td>\n",
       "      <td>13.39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>Valparaiso</td>\n",
       "      <td>UNC</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>Valparaiso</td>\n",
       "      <td>32</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2344</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>210</td>\n",
       "      <td>562</td>\n",
       "      <td>564</td>\n",
       "      <td>Valparaiso</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNC</td>\n",
       "      <td>13.39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>Wake Forest</td>\n",
       "      <td>UNC</td>\n",
       "      <td>82</td>\n",
       "      <td>69</td>\n",
       "      <td>Wake Forest</td>\n",
       "      <td>31</td>\n",
       "      <td>11.45</td>\n",
       "      <td>8.85</td>\n",
       "      <td>2257</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>210</td>\n",
       "      <td>562</td>\n",
       "      <td>564</td>\n",
       "      <td>Wake Forest</td>\n",
       "      <td>14.12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>UNC</td>\n",
       "      <td>13.39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                   Home Away  Home_Score  Away_Score  \\\n",
       "0  2010  Florida International  UNC          72          88   \n",
       "1  2010            Albany (NY)  UNC          70          87   \n",
       "2  2010         William & Mary  UNC          72          80   \n",
       "3  2010             Valparaiso  UNC          77          88   \n",
       "4  2010            Wake Forest  UNC          82          69   \n",
       "\n",
       "               Team_Home  G_Home  SRS_Home  SOS_Home  Tm._Home    ...      \\\n",
       "0  Florida International      32    -12.81     -2.74      2176    ...       \n",
       "1            Albany (NY)      32    -11.94     -5.53      2007    ...       \n",
       "2         William & Mary      33      2.82      1.63      2213    ...       \n",
       "3             Valparaiso      32     -2.90      0.34      2344    ...       \n",
       "4            Wake Forest      31     11.45      8.85      2257    ...       \n",
       "\n",
       "   STL_Away  BLK_Away  TOV_Away  PF_Away              Team_Home  AdjEM_Home  \\\n",
       "0       250       210       562      564  Florida International      -14.45   \n",
       "1       250       210       562      564            Albany (NY)      -13.16   \n",
       "2       250       210       562      564         William & Mary        6.58   \n",
       "3       250       210       562      564             Valparaiso       -0.92   \n",
       "4       250       210       562      564            Wake Forest       14.12   \n",
       "\n",
       "   Seed_Home  Team_Away  AdjEM_Away  Seed_Away  \n",
       "0        NaN        UNC       13.39        NaN  \n",
       "1        NaN        UNC       13.39        NaN  \n",
       "2        NaN        UNC       13.39        NaN  \n",
       "3        NaN        UNC       13.39        NaN  \n",
       "4        9.0        UNC       13.39        NaN  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the paths to the scores data \n",
    "save_path = '../Data/Combined_Data/'\n",
    "\n",
    "# Save the joined tables in dictionaries\n",
    "regular = {}\n",
    "march = {}\n",
    "\n",
    "# We need to first join datasets from the same year\n",
    "for year in range(2010, this_year):\n",
    "    \n",
    "    # Get only the columns we need from the kenpom data\n",
    "    kp = kenpom_data[year][['Team', 'AdjEM', 'Seed']]\n",
    "    \n",
    "    # Join the dataframes to get basic statistics data and kenpom (seed, adj_em) for both home and away team\n",
    "    regular[year] = pd.merge(regular_season[year], stats_data[year], left_on='Home', right_on='Team', sort=False)\n",
    "    regular[year] = pd.merge(regular[year], stats_data[year], left_on='Away', right_on='Team', \n",
    "                             suffixes=('_Home', '_Away'), sort=False)\n",
    "    regular[year] = pd.merge(regular[year], kp, left_on='Home', right_on='Team', sort=False)\n",
    "    regular[year] = pd.merge(regular[year], kp, left_on='Away', right_on='Team', \n",
    "                             suffixes=('_Home', '_Away'), sort=False)\n",
    "    \n",
    "    # Do the same for the march data (No march data for this year yet)\n",
    "    if year < this_year - 1:\n",
    "        march[year] = pd.merge(march_madness[year], stats_data[year], left_on='Home', right_on='Team', sort=False)\n",
    "        march[year] = pd.merge(march[year], stats_data[year], left_on='Away', right_on='Team', \n",
    "                                 suffixes=('_Home', '_Away'), sort=False)\n",
    "        march[year] = pd.merge(march[year], kp, left_on='Home', right_on='Team', sort=False)\n",
    "        march[year] = pd.merge(march[year], kp, left_on='Away', right_on='Team', \n",
    "                                 suffixes=('_Home', '_Away'), sort=False)\n",
    "\n",
    "        # Move non-tournament games to regular season data\n",
    "        other_games = march[year][march[year]['Seed_Home'].isnull()]\n",
    "        regular[year] = pd.concat([regular[year], other_games], ignore_index=True)\n",
    "        march[year].drop(other_games.index, inplace=True)\n",
    "    \n",
    "    # Add a column to indicate the year\n",
    "    regular[year].insert(0, 'Year', year)\n",
    "    if year < this_year - 1:\n",
    "        march[year].insert(0, 'Year', year)\n",
    "    \n",
    "# Combine the data for every year\n",
    "regular_df = pd.concat(regular, ignore_index=True)\n",
    "march_df = pd.concat(march, ignore_index=True)\n",
    "\n",
    "# Save the data to csv files\n",
    "regular_df.to_csv('{0}Basic.csv'.format(save_path))\n",
    "    \n",
    "# Lets take a look at one of the data sets\n",
    "print(\"There are {} games in the basic statistics dataset.\".format(len(regular_df)))\n",
    "regular_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
